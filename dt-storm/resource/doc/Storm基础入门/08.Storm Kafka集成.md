集成描述：
    Storm作为消费者从Kafka队列中提取消息

集成步骤:
    (1)在Maven工程pom.xml文件中添加storm-kafka依赖，
	    <dependency>
            <groupId>org.apache.storm</groupId>
            <artifactId>storm-kafka</artifactId>
            <version>1.0.3</version>
        </dependency>
		
		还要添加kafka的相关依赖,如下：
		<dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_2.11</artifactId>
            <version>0.10.0.1</version>
        </dependency>
		
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>0.10.0.1</version>
        </dependency>
		
		注意：Storm官方文档中kafka依赖需要去除log4j的依赖,修改如下：
		<dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka_2.11</artifactId>
            <version>0.10.0.1</version>
            <exclusions>
                <exclusion>
                    <groupId>org.apache.zookeeper</groupId>
                    <artifactId>zookeeper</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>log4j</groupId>
                    <artifactId>log4j</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
		
	(2)启动Kafka+Storm集群
	
	(3)编写代码，主要与原生的Storm Spout不同的就是配置KafkaSpout，关键代码如下:
	    ...
	    //配置zk连接串
        BrokerHosts hosts = new ZkHosts(ZK_HOSTS);

        //Spout配置
        SpoutConfig spoutConfig = new SpoutConfig(hosts, TOPIC, ZK_ROOT, UUID.randomUUID().toString());
        spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
        KafkaSpout kafkaSpout = new KafkaSpout(spoutConfig);

        //设置Spout
        builder.setSpout("kafkaspout", kafkaSpout).setNumTasks(2);
        //设置bolt
        builder.setBolt("split-bolt" , new SplitBolt(), 2).shuffleGrouping("kafkaspout").setNumTasks(2);
        builder.setBolt("counter-bolt", new CountBolt()).fieldsGrouping("split-bolt", new Fields("word")).setNumTasks(4);
		...

	代码参见:com.it18zhang.storm.kafka.wc.*
	